{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "1UNxfGkpXpfrVoFtdeadM4BGICct91kPV",
      "authorship_tag": "ABX9TyOh80dEujkQ7PdfW4TBmACi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lalitgiri77480/Hyperparameter_Automation_Mlops/blob/master/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUiIqDnicr61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import MobileNet\n",
        "\n",
        "# MobileNet was designed to work on 224 x 224 pixel input images sizes\n",
        "img_rows, img_cols = 224, 224 \n",
        "\n",
        "# Re-loads the MobileNet model without the top or FC layers\n",
        "MobileNet = MobileNet(weights = 'imagenet', \n",
        "                 include_top = False, \n",
        "                 input_shape = (img_rows, img_cols, 3))\n",
        "\n",
        "# Here we freeze the last 4 layers \n",
        "# Layers are set to trainable as True by default\n",
        "for layer in MobileNet.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "# Let's print our layers \n",
        "for (i,layer) in enumerate(MobileNet.layers):\n",
        "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-_Pca--gdFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addTopModelMobileNet(bottom_model, num_classes):\n",
        "    \"\"\"creates the top or head of the model that will be \n",
        "    placed ontop of the bottom layers\"\"\"\n",
        "\n",
        "    top_model = bottom_model.output\n",
        "    top_model = GlobalAveragePooling2D()(top_model)\n",
        "    top_model = Dense(1024,activation='relu')(top_model)\n",
        "    top_model = Dense(1024,activation='relu')(top_model)\n",
        "    top_model = Dense(512,activation='relu')(top_model)\n",
        "    top_model = Dense(256,activation='relu')(top_model)\n",
        "    top_model = Dense(128,activation='relu')(top_model)\n",
        "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
        "    return top_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbnXNlVrgj3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "\n",
        "# Set our class number to 2 (Corona , normal)\n",
        "num_classes = 2\n",
        "\n",
        "FC_Head = addTopModelMobileNet(MobileNet, num_classes)\n",
        "\n",
        "model = Model(inputs = MobileNet.input, outputs = FC_Head)\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esqoWobmgti6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "!pwd\n",
        "train_data_dir = 'drive/My Drive/corona/train/'\n",
        "validation_data_dir = 'drive/My Drive/corona/test/'\n",
        "\n",
        "# Let's use some data augmentaiton \n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=45,\n",
        "      width_shift_range=0.3,\n",
        "      height_shift_range=0.3,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        " \n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        " \n",
        "# set our batch size (typically on most mid tier systems we'll use 16-32)\n",
        "batch_size = 32\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDtn0U9RhaWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "                     \n",
        "checkpoint = ModelCheckpoint(\"corona.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          min_delta = 0, \n",
        "                          patience = 3,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True)\n",
        "\n",
        "# we put our call backs into a callback list\n",
        "callbacks = [earlystop, checkpoint]\n",
        "\n",
        "# We use a very small learning rate \n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = RMSprop(lr = 0.001),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# Enter the number of training and validation samples here\n",
        "nb_train_samples = 224\n",
        "nb_validation_samples = 20\n",
        "\n",
        "# We only train 5 EPOCHS \n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = nb_train_samples // batch_size,\n",
        "    epochs = epochs,\n",
        "    callbacks = callbacks,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = nb_validation_samples // batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwR7pTEGyJT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.history['accuracy'][0])\n",
        "\n",
        "mod =str(model.layers)\n",
        "accuracy = str(history.history['accuracy'][0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if history.history['accuracy'][0] >= .80:\n",
        "    import smtplib\n",
        "    # creates SMTP session \n",
        "    s = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "    # start TLS for security \n",
        "    s.starttls()\n",
        "\n",
        "    # Authentication \n",
        "    s.login(\"1998lalitgiri123@gmail.com\", \"Lalit@123\")\n",
        "\n",
        "\n",
        "    # message to be sent \n",
        "    message1 = accuracy\n",
        "    message2 = mod\n",
        "    l={\"accuracy\":accuracy}\n",
        "\n",
        "    # sending the mail \n",
        "    s.sendmail(\"1998lalitgiri123@gmail.com\", \"1998lalitgiri123@gmail.com\",  message1)\n",
        "    s.sendmail(\"1998lalitgiri123@gmail.com\", \"1998lalitgiri123@gmail.com\", message2)\n",
        "\n",
        "    # terminating the session \n",
        "    s.quit()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}